{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e709754b-ce19-4867-bbcb-968728746298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\brian\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Brian\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94b46d7-5325-4113-b707-ca50da1992f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5033 records from C:\\Users\\Brian\\.cache\\kagglehub\\datasets\\jvanark\\nvidia-daily-stock-price-data\\versions\\2\\nvidia_stock_prices.csv\n",
      "Initial Data Summary: 5033 records, 6 columns\n",
      "Dropped columns: ['Open', 'Close']\n",
      "Added columns: dict_keys(['New_Column']) with default values.\n",
      "Data converted to JSON and saved to output_data.json\n",
      "Data stored in SQLite table 'stock_prices'\n",
      "Post-processing Data Summary: 5033 records, 5 columns\n",
      "Loaded 42 records from API (JSON)\n",
      "Initial Data Summary: 42 records, 3 columns\n",
      "Added columns: dict_keys(['New_Column']) with default values.\n",
      "Data converted to JSON and saved to output_data.json\n",
      "Data stored in SQLite table 'stock_prices'\n",
      "Post-processing Data Summary: 42 records, 4 columns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "import requests\n",
    "import kagglehub\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"jvanark/nvidia-daily-stock-price-data\")\n",
    "csv_file = os.path.join(dataset_path, \"nvidia_stock_prices.csv\")\n",
    "\n",
    "def load_data(file_path_or_url, api_key=None):\n",
    "    # Check if the input is a URL\n",
    "    if file_path_or_url.startswith('http://') or file_path_or_url.startswith('https://'):\n",
    "        params = {'access_key': api_key} if api_key else {}\n",
    "        response = requests.get(file_path_or_url, params=params)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Error fetching data: {response.status_code}\")\n",
    "        \n",
    "        content_type = response.headers['Content-Type']\n",
    "        \n",
    "        if 'application/json' in content_type:\n",
    "            data = pd.DataFrame(response.json()['data'])  # Adjusted for MarketStack's API response structure\n",
    "            print(f\"Loaded {len(data)} records from API (JSON)\")\n",
    "            return data\n",
    "        elif 'text/csv' in content_type:\n",
    "            from io import StringIO\n",
    "            data = pd.read_csv(StringIO(response.text))\n",
    "            print(f\"Loaded {len(data)} records from API (CSV)\")\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported Content-Type from API!\")\n",
    "    \n",
    "    elif file_path_or_url.endswith('.csv'):\n",
    "        data = pd.read_csv(file_path_or_url)\n",
    "        print(f\"Loaded {len(data)} records from {file_path_or_url}\")\n",
    "        return data\n",
    "    elif file_path_or_url.endswith('.json'):\n",
    "        with open(file_path_or_url, 'r') as f:\n",
    "            data = pd.DataFrame(json.load(f))\n",
    "        print(f\"Loaded {len(data)} records from {file_path_or_url}\")\n",
    "        return data\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format!\")\n",
    "\n",
    "def modify_columns(data, drop_columns=None, add_columns=None):\n",
    "    if drop_columns:\n",
    "        data = data.drop(columns=drop_columns)\n",
    "        print(f\"Dropped columns: {drop_columns}\")\n",
    "    if add_columns:\n",
    "        for col, default_value in add_columns.items():\n",
    "            data[col] = default_value\n",
    "        print(f\"Added columns: {add_columns.keys()} with default values.\")    \n",
    "    return data\n",
    "\n",
    "def convert_data(data, output_format):\n",
    "    if output_format == 'csv':\n",
    "        output_file = \"output_data.csv\"\n",
    "        data.to_csv(output_file, index=False)\n",
    "        print(f\"Data converted to CSV and saved to {output_file}\")\n",
    "    elif output_format == 'json':\n",
    "        output_file = \"output_data.json\"\n",
    "        data.to_json(output_file, orient='records', lines=True)\n",
    "        print(f\"Data converted to JSON and saved to {output_file}\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported output format!\")\n",
    "    return output_file\n",
    "\n",
    "def store_in_sqlite(data, table_name):\n",
    "    conn = sqlite3.connect('etl_data.db')\n",
    "    data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    print(f\"Data stored in SQLite table '{table_name}'\")\n",
    "    conn.close()\n",
    "\n",
    "def etl_process(file_path_or_url, output_format='csv', store_sql=False, drop_columns=None, add_columns=None, api_key=None):\n",
    "    try:\n",
    "        data = load_data(file_path_or_url, api_key=api_key)\n",
    "        print(f\"Initial Data Summary: {len(data)} records, {len(data.columns)} columns\")\n",
    "        data = modify_columns(data, drop_columns, add_columns)\n",
    "        converted_file = convert_data(data, output_format)\n",
    "        if store_sql:\n",
    "            store_in_sqlite(data, table_name=\"stock_prices\")\n",
    "        print(f\"Post-processing Data Summary: {len(data)} records, {len(data.columns)} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during ETL process: {str(e)}\")\n",
    "\n",
    "# Example usage with a local CSV file\n",
    "etl_process(\n",
    "    csv_file, \n",
    "    output_format='json', \n",
    "    store_sql=True, \n",
    "    drop_columns=['Open', 'Close'],  \n",
    "    add_columns={'New_Column': 'default_value'} \n",
    ")\n",
    "\n",
    "# Example usage with an API URL (with API key for MarketStack)\n",
    "api_url = 'http://api.marketstack.com/v1/currencies'\n",
    "api_key = 'api-key'  # Replace with your actual API key\n",
    "\n",
    "etl_process(\n",
    "    api_url, \n",
    "    output_format='json', \n",
    "    store_sql=True, \n",
    "    api_key=api_key,\n",
    "    drop_columns=None, \n",
    "    add_columns={'New_Column': 'default_value'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392d804-f592-41f7-a174-92c261692d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
